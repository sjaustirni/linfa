<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `algorithms/linfa-svm/src/lib.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>lib.rs - source</title><link rel="stylesheet" type="text/css" href="../../normalize.css"><link rel="stylesheet" type="text/css" href="../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" type="text/css" href="../../light.css"  id="themeStyle"><link rel="stylesheet" type="text/css" href="../../dark.css" disabled ><link rel="stylesheet" type="text/css" href="../../ayu.css" disabled ><script id="default-settings"></script><script src="../../storage.js"></script><noscript><link rel="stylesheet" href="../../noscript.css"></noscript><link rel="icon" type="image/svg+xml" href="../../favicon.svg">
<link rel="alternate icon" type="image/png" href="../../favicon-16x16.png">
<link rel="alternate icon" type="image/png" href="../../favicon-32x32.png"><style type="text/css">#crate-search{background-image:url("../../down-arrow.svg");}</style></head><body class="rustdoc source"><!--[if lte IE 8]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><div class="sidebar-menu">&#9776;</div><a href='../../linfa_svm/index.html'><div class='logo-container rust-logo'><img src='../../rust-logo.png' alt='logo'></div></a></nav><div class="theme-picker"><button id="theme-picker" aria-label="Pick another theme!" aria-haspopup="menu"><img src="../../brush.svg" width="18" alt="Pick another theme!"></button><div id="theme-choices" role="menu"></div></div><script src="../../theme.js"></script><nav class="sub"><form class="search-form"><div class="search-container"><div><select id="crate-search"><option value="All crates">All crates</option></select><input class="search-input" name="search" disabled autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"></div><button type="button" class="help-button">?</button>
                <a id="settings-menu" href="../../settings.html"><img src="../../wheel.svg" width="18" alt="Change settings"></a></div></form></nav><section id="main" class="content"><pre class="line-numbers"><span id="1">  1</span>
<span id="2">  2</span>
<span id="3">  3</span>
<span id="4">  4</span>
<span id="5">  5</span>
<span id="6">  6</span>
<span id="7">  7</span>
<span id="8">  8</span>
<span id="9">  9</span>
<span id="10"> 10</span>
<span id="11"> 11</span>
<span id="12"> 12</span>
<span id="13"> 13</span>
<span id="14"> 14</span>
<span id="15"> 15</span>
<span id="16"> 16</span>
<span id="17"> 17</span>
<span id="18"> 18</span>
<span id="19"> 19</span>
<span id="20"> 20</span>
<span id="21"> 21</span>
<span id="22"> 22</span>
<span id="23"> 23</span>
<span id="24"> 24</span>
<span id="25"> 25</span>
<span id="26"> 26</span>
<span id="27"> 27</span>
<span id="28"> 28</span>
<span id="29"> 29</span>
<span id="30"> 30</span>
<span id="31"> 31</span>
<span id="32"> 32</span>
<span id="33"> 33</span>
<span id="34"> 34</span>
<span id="35"> 35</span>
<span id="36"> 36</span>
<span id="37"> 37</span>
<span id="38"> 38</span>
<span id="39"> 39</span>
<span id="40"> 40</span>
<span id="41"> 41</span>
<span id="42"> 42</span>
<span id="43"> 43</span>
<span id="44"> 44</span>
<span id="45"> 45</span>
<span id="46"> 46</span>
<span id="47"> 47</span>
<span id="48"> 48</span>
<span id="49"> 49</span>
<span id="50"> 50</span>
<span id="51"> 51</span>
<span id="52"> 52</span>
<span id="53"> 53</span>
<span id="54"> 54</span>
<span id="55"> 55</span>
<span id="56"> 56</span>
<span id="57"> 57</span>
<span id="58"> 58</span>
<span id="59"> 59</span>
<span id="60"> 60</span>
<span id="61"> 61</span>
<span id="62"> 62</span>
<span id="63"> 63</span>
<span id="64"> 64</span>
<span id="65"> 65</span>
<span id="66"> 66</span>
<span id="67"> 67</span>
<span id="68"> 68</span>
<span id="69"> 69</span>
<span id="70"> 70</span>
<span id="71"> 71</span>
<span id="72"> 72</span>
<span id="73"> 73</span>
<span id="74"> 74</span>
<span id="75"> 75</span>
<span id="76"> 76</span>
<span id="77"> 77</span>
<span id="78"> 78</span>
<span id="79"> 79</span>
<span id="80"> 80</span>
<span id="81"> 81</span>
<span id="82"> 82</span>
<span id="83"> 83</span>
<span id="84"> 84</span>
<span id="85"> 85</span>
<span id="86"> 86</span>
<span id="87"> 87</span>
<span id="88"> 88</span>
<span id="89"> 89</span>
<span id="90"> 90</span>
<span id="91"> 91</span>
<span id="92"> 92</span>
<span id="93"> 93</span>
<span id="94"> 94</span>
<span id="95"> 95</span>
<span id="96"> 96</span>
<span id="97"> 97</span>
<span id="98"> 98</span>
<span id="99"> 99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
<span id="218">218</span>
<span id="219">219</span>
<span id="220">220</span>
<span id="221">221</span>
<span id="222">222</span>
<span id="223">223</span>
<span id="224">224</span>
<span id="225">225</span>
<span id="226">226</span>
<span id="227">227</span>
<span id="228">228</span>
<span id="229">229</span>
<span id="230">230</span>
<span id="231">231</span>
<span id="232">232</span>
<span id="233">233</span>
<span id="234">234</span>
<span id="235">235</span>
<span id="236">236</span>
<span id="237">237</span>
<span id="238">238</span>
<span id="239">239</span>
<span id="240">240</span>
<span id="241">241</span>
<span id="242">242</span>
<span id="243">243</span>
<span id="244">244</span>
<span id="245">245</span>
<span id="246">246</span>
<span id="247">247</span>
<span id="248">248</span>
<span id="249">249</span>
<span id="250">250</span>
<span id="251">251</span>
<span id="252">252</span>
<span id="253">253</span>
<span id="254">254</span>
<span id="255">255</span>
<span id="256">256</span>
<span id="257">257</span>
<span id="258">258</span>
<span id="259">259</span>
<span id="260">260</span>
<span id="261">261</span>
<span id="262">262</span>
<span id="263">263</span>
<span id="264">264</span>
<span id="265">265</span>
<span id="266">266</span>
<span id="267">267</span>
<span id="268">268</span>
<span id="269">269</span>
<span id="270">270</span>
<span id="271">271</span>
<span id="272">272</span>
<span id="273">273</span>
<span id="274">274</span>
<span id="275">275</span>
<span id="276">276</span>
<span id="277">277</span>
<span id="278">278</span>
<span id="279">279</span>
<span id="280">280</span>
<span id="281">281</span>
<span id="282">282</span>
<span id="283">283</span>
<span id="284">284</span>
<span id="285">285</span>
<span id="286">286</span>
<span id="287">287</span>
<span id="288">288</span>
<span id="289">289</span>
<span id="290">290</span>
<span id="291">291</span>
<span id="292">292</span>
<span id="293">293</span>
<span id="294">294</span>
<span id="295">295</span>
<span id="296">296</span>
<span id="297">297</span>
<span id="298">298</span>
<span id="299">299</span>
<span id="300">300</span>
<span id="301">301</span>
<span id="302">302</span>
<span id="303">303</span>
<span id="304">304</span>
<span id="305">305</span>
<span id="306">306</span>
<span id="307">307</span>
<span id="308">308</span>
<span id="309">309</span>
<span id="310">310</span>
<span id="311">311</span>
<span id="312">312</span>
<span id="313">313</span>
<span id="314">314</span>
<span id="315">315</span>
<span id="316">316</span>
<span id="317">317</span>
<span id="318">318</span>
<span id="319">319</span>
<span id="320">320</span>
<span id="321">321</span>
<span id="322">322</span>
<span id="323">323</span>
<span id="324">324</span>
<span id="325">325</span>
<span id="326">326</span>
<span id="327">327</span>
<span id="328">328</span>
<span id="329">329</span>
<span id="330">330</span>
<span id="331">331</span>
<span id="332">332</span>
<span id="333">333</span>
<span id="334">334</span>
<span id="335">335</span>
<span id="336">336</span>
<span id="337">337</span>
<span id="338">338</span>
<span id="339">339</span>
<span id="340">340</span>
<span id="341">341</span>
<span id="342">342</span>
<span id="343">343</span>
<span id="344">344</span>
<span id="345">345</span>
<span id="346">346</span>
<span id="347">347</span>
<span id="348">348</span>
<span id="349">349</span>
<span id="350">350</span>
<span id="351">351</span>
<span id="352">352</span>
<span id="353">353</span>
<span id="354">354</span>
<span id="355">355</span>
<span id="356">356</span>
<span id="357">357</span>
<span id="358">358</span>
<span id="359">359</span>
<span id="360">360</span>
<span id="361">361</span>
<span id="362">362</span>
<span id="363">363</span>
<span id="364">364</span>
<span id="365">365</span>
<span id="366">366</span>
<span id="367">367</span>
<span id="368">368</span>
<span id="369">369</span>
<span id="370">370</span>
<span id="371">371</span>
<span id="372">372</span>
<span id="373">373</span>
<span id="374">374</span>
<span id="375">375</span>
<span id="376">376</span>
<span id="377">377</span>
<span id="378">378</span>
<span id="379">379</span>
<span id="380">380</span>
<span id="381">381</span>
<span id="382">382</span>
<span id="383">383</span>
<span id="384">384</span>
<span id="385">385</span>
<span id="386">386</span>
<span id="387">387</span>
<span id="388">388</span>
<span id="389">389</span>
<span id="390">390</span>
<span id="391">391</span>
<span id="392">392</span>
<span id="393">393</span>
<span id="394">394</span>
<span id="395">395</span>
</pre><div class="example-wrap"><pre class="rust ">
<span class="doccomment">//! # Support Vector Machines</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Support Vector Machines are a major branch of machine learning models and offer classification or</span>
<span class="doccomment">//! regression analysis of labeled datasets. They seek a discriminant, which separates the data in</span>
<span class="doccomment">//! an optimal way, e.g. have the fewest numbers of miss-classifications and maximizes the margin</span>
<span class="doccomment">//! between positive and negative classes. A support vector</span>
<span class="doccomment">//! contributes to the discriminant and is therefore important for the classification/regression</span>
<span class="doccomment">//! task. The balance between the number of support vectors and model performance can be controlled</span>
<span class="doccomment">//! with hyperparameters.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! More details can be found [here](https://en.wikipedia.org/wiki/Support_vector_machine)</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Available parameters in Classification and Regression</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! For supervised classification tasks the C or Nu values are used to control this balance. In</span>
<span class="doccomment">//! [fit_c](SVClassify/fn.fit_c) the</span>
<span class="doccomment">//! C value controls the penalty given to missclassification and should be in the interval (0, inf). In</span>
<span class="doccomment">//! [fit_nu](SVClassify/fn.fit_nu.html) the Nu value controls the number of support vectors and should be in the interval (0, 1].</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! For supervised classification with just one class of data a special classifier is available in</span>
<span class="doccomment">//! [fit_one_class](SVClassify/fn.fit_one_class.html). It also accepts a Nu value.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! For support vector regression two flavors are available. With</span>
<span class="doccomment">//! [fit_epsilon](SVRegress/fn.fit_epsilon.html) a regression task is learned while minimizing deviation</span>
<span class="doccomment">//! larger than epsilon. In [fit_nu](SVRegress/fn.fit_nu.html) the parameter epsilon is replaced with Nu</span>
<span class="doccomment">//! again and should be in the interval (0, 1]</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## Kernel Methods</span>
<span class="doccomment">//! Normally the resulting discriminant is linear, but with [Kernel Methods](https://en.wikipedia.org/wiki/Kernel_method) non-linear relations between the input features</span>
<span class="doccomment">//! can be learned in order improve the performance of the model.</span>
<span class="doccomment">//!  </span>
<span class="doccomment">//! For example to transform a dataset into a sparse RBF kernel with 10 non-zero distances you can</span>
<span class="doccomment">//! use `linfa_kernel`:</span>
<span class="doccomment">//! ```rust, ignore</span>
<span class="doccomment">//! use linfa_kernel::Kernel;</span>
<span class="doccomment">//! let train_kernel = Kernel::params()</span>
<span class="doccomment">//!     .method(KernelMethod::Gaussian(30.0))</span>
<span class="doccomment">//!     .transform(&amp;train);</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # The solver</span>
<span class="doccomment">//! This implementation uses Sequential Minimal Optimization, a widely used optimization tool for</span>
<span class="doccomment">//! convex problems. It selects in each optimization step two variables and updates the variables.</span>
<span class="doccomment">//! In each step it performs:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! 1. Find a variable, which violates the KKT conditions for the optimization problem</span>
<span class="doccomment">//! 2. Pick a second variables and crate a pair (a1, a2)</span>
<span class="doccomment">//! 3. Optimize the pair (a1, a2)</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! After a couple of iterations the solution may be optimal.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # Example</span>
<span class="doccomment">//! The wine quality data consists of 11 features, like &quot;acid&quot;, &quot;sugar&quot;, &quot;sulfur dioxide&quot;, and</span>
<span class="doccomment">//! groups the quality into worst 3 to best 8. These are unified to good 8-7 and bad 3-6 to get a</span>
<span class="doccomment">//! binary classification task.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! With an RBF kernel and C-Support Vector Classification an</span>
<span class="doccomment">//! accuracy of 88.7% is reached within 79535 iterations and 316 support vectors. You can find the</span>
<span class="doccomment">//! example [here](https://github.com/rust-ml/linfa/blob/master/linfa-svm/examples/winequality.rs).</span>
<span class="doccomment">//! ```ignore</span>
<span class="doccomment">//! Fit SVM classifier with #1440 training points</span>
<span class="doccomment">//! Exited after 79535 iterations with obj = -46317.55802870996 and 316 support vectors</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! classes    | bad        | good</span>
<span class="doccomment">//! bad        | 133        | 9</span>
<span class="doccomment">//! good       | 9          | 8</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! accuracy 0.8867925, MCC 0.40720797</span>
<span class="doccomment">//! ```</span>
<span class="kw">use</span> <span class="ident">linfa</span>::<span class="ident">Float</span>;
<span class="kw">use</span> <span class="ident">ndarray</span>::{<span class="ident">ArrayBase</span>, <span class="ident">Data</span>, <span class="ident">Ix1</span>};

<span class="kw">use</span> <span class="ident">std</span>::<span class="ident">fmt</span>;
<span class="kw">use</span> <span class="ident">std</span>::<span class="ident">marker</span>::<span class="ident">PhantomData</span>;

<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;serde&quot;</span>)]</span>
<span class="kw">use</span> <span class="ident">serde_crate</span>::{<span class="ident">Deserialize</span>, <span class="ident">Serialize</span>};

<span class="kw">mod</span> <span class="ident">classification</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">error</span>;
<span class="kw">mod</span> <span class="ident">permutable_kernel</span>;
<span class="kw">mod</span> <span class="ident">regression</span>;
<span class="kw">pub</span> <span class="kw">mod</span> <span class="ident">solver_smo</span>;

<span class="kw">use</span> <span class="ident">linfa_kernel</span>::{<span class="ident">Kernel</span>, <span class="ident">KernelMethod</span>, <span class="ident">KernelParams</span>};
<span class="kw">pub</span> <span class="kw">use</span> <span class="ident">solver_smo</span>::{<span class="ident">SeparatingHyperplane</span>, <span class="ident">SolverParams</span>};

<span class="kw">use</span> <span class="ident">std</span>::<span class="ident">ops</span>::<span class="ident">Mul</span>;

<span class="doccomment">/// SVM Hyperparameters</span>
<span class="doccomment">///</span>
<span class="doccomment">/// The SVM fitting process can be controlled in different ways. For classification the C and Nu</span>
<span class="doccomment">/// parameters control the ratio of support vectors and accuracy, eps controls the required</span>
<span class="doccomment">/// precision. After setting the desired parameters a model can be fitted by calling `fit`.</span>
<span class="doccomment">///</span>
<span class="doccomment">/// ## Example</span>
<span class="doccomment">///</span>
<span class="doccomment">/// ```ignore</span>
<span class="doccomment">/// let model = Svm::params()</span>
<span class="doccomment">///     .eps(0.1f64)</span>
<span class="doccomment">///     .shrinking(true)</span>
<span class="doccomment">///     .nu_weight(0.1)</span>
<span class="doccomment">///     .fit(&amp;dataset);</span>
<span class="doccomment">/// ```</span>
<span class="doccomment">///</span>
<span class="kw">pub</span> <span class="kw">struct</span> <span class="ident">SvmParams</span><span class="op">&lt;</span><span class="ident">F</span>: <span class="ident">Float</span>, <span class="ident">T</span><span class="op">&gt;</span> {
    <span class="ident">c</span>: <span class="prelude-ty">Option</span><span class="op">&lt;</span>(<span class="ident">F</span>, <span class="ident">F</span>)<span class="op">&gt;</span>,
    <span class="ident">nu</span>: <span class="prelude-ty">Option</span><span class="op">&lt;</span>(<span class="ident">F</span>, <span class="ident">F</span>)<span class="op">&gt;</span>,
    <span class="ident">solver_params</span>: <span class="ident">SolverParams</span><span class="op">&lt;</span><span class="ident">F</span><span class="op">&gt;</span>,
    <span class="ident">phantom</span>: <span class="ident">PhantomData</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span>,
    <span class="ident">kernel</span>: <span class="ident">KernelParams</span><span class="op">&lt;</span><span class="ident">F</span><span class="op">&gt;</span>,
}

<span class="kw">impl</span><span class="op">&lt;</span><span class="ident">F</span>: <span class="ident">Float</span>, <span class="ident">T</span><span class="op">&gt;</span> <span class="ident">SvmParams</span><span class="op">&lt;</span><span class="ident">F</span>, <span class="ident">T</span><span class="op">&gt;</span> {
    <span class="doccomment">/// Set stopping condition</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// This parameter controls the stopping condition. It checks whether the sum of gradients of</span>
    <span class="doccomment">/// the max violating pair is below this threshold and then stops the optimization proces.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">eps</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">new_eps</span>: <span class="ident">F</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">solver_params</span>.<span class="ident">eps</span> <span class="op">=</span> <span class="ident">new_eps</span>;
        <span class="self">self</span>
    }

    <span class="doccomment">/// Shrink active variable set</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// This parameter controls whether the active variable set is shrinked or not. This can speed</span>
    <span class="doccomment">/// up the optimization process, but may degredade the solution performance.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">shrinking</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">shrinking</span>: <span class="ident">bool</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">solver_params</span>.<span class="ident">shrinking</span> <span class="op">=</span> <span class="ident">shrinking</span>;

        <span class="self">self</span>
    }

    <span class="doccomment">/// Set the kernel to use for training</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// This parameter specifies a mapping of input records to a new feature space by means</span>
    <span class="doccomment">/// of the distance function between any couple of points mapped to such new space.</span>
    <span class="doccomment">/// The SVM then applies a linear separation in the new feature space that may result in</span>
    <span class="doccomment">/// a non linear partitioning of the original input space, thus increasing the expressiveness of</span>
    <span class="doccomment">/// this model. To use the &quot;base&quot; SVM model it suffices to choose a `Linear` kernel.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">with_kernel_params</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">kernel</span>: <span class="ident">KernelParams</span><span class="op">&lt;</span><span class="ident">F</span><span class="op">&gt;</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">kernel</span> <span class="op">=</span> <span class="ident">kernel</span>;

        <span class="self">self</span>
    }

    <span class="doccomment">/// Sets the model to use the Gaussian kernel. For this kernel the</span>
    <span class="doccomment">/// distance between two points is computed as: `d(x, x&#39;) = exp(-norm(x - x&#39;)/eps)`</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">gaussian_kernel</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">eps</span>: <span class="ident">F</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">kernel</span> <span class="op">=</span> <span class="ident">Kernel</span>::<span class="ident">params</span>().<span class="ident">method</span>(<span class="ident">KernelMethod</span>::<span class="ident">Gaussian</span>(<span class="ident">eps</span>));

        <span class="self">self</span>
    }

    <span class="doccomment">/// Sets the model to use the Polynomial kernel. For this kernel the</span>
    <span class="doccomment">/// distance between two points is computed as: `d(x, x&#39;) = (&lt;x, x&#39;&gt; + costant)^(degree)`</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">polynomial_kernel</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">constant</span>: <span class="ident">F</span>, <span class="ident">degree</span>: <span class="ident">F</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">kernel</span> <span class="op">=</span> <span class="ident">Kernel</span>::<span class="ident">params</span>().<span class="ident">method</span>(<span class="ident">KernelMethod</span>::<span class="ident">Polynomial</span>(<span class="ident">constant</span>, <span class="ident">degree</span>));

        <span class="self">self</span>
    }

    <span class="doccomment">/// Sets the model to use the Linear kernel. For this kernel the</span>
    <span class="doccomment">/// distance between two points is computed as : `d(x, x&#39;) = &lt;x, x&#39;&gt;`</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">linear_kernel</span>(<span class="kw-2">mut</span> <span class="self">self</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">kernel</span> <span class="op">=</span> <span class="ident">Kernel</span>::<span class="ident">params</span>().<span class="ident">method</span>(<span class="ident">KernelMethod</span>::<span class="ident">Linear</span>);

        <span class="self">self</span>
    }
}

<span class="kw">impl</span><span class="op">&lt;</span><span class="ident">F</span>: <span class="ident">Float</span>, <span class="ident">T</span><span class="op">&gt;</span> <span class="ident">SvmParams</span><span class="op">&lt;</span><span class="ident">F</span>, <span class="ident">T</span><span class="op">&gt;</span> {
    <span class="doccomment">/// Set the C value for positive and negative samples.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">pos_neg_weights</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">c_pos</span>: <span class="ident">F</span>, <span class="ident">c_neg</span>: <span class="ident">F</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">c</span> <span class="op">=</span> <span class="prelude-val">Some</span>((<span class="ident">c_pos</span>, <span class="ident">c_neg</span>));
        <span class="self">self</span>.<span class="ident">nu</span> <span class="op">=</span> <span class="prelude-val">None</span>;

        <span class="self">self</span>
    }

    <span class="doccomment">/// Set the Nu value for classification</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// The Nu value should lie in range [0, 1] and sets the relation between support vectors and</span>
    <span class="doccomment">/// solution performance.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">nu_weight</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">nu</span>: <span class="ident">F</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">nu</span> <span class="op">=</span> <span class="prelude-val">Some</span>((<span class="ident">nu</span>, <span class="ident">nu</span>));
        <span class="self">self</span>.<span class="ident">c</span> <span class="op">=</span> <span class="prelude-val">None</span>;

        <span class="self">self</span>
    }
}

<span class="kw">impl</span><span class="op">&lt;</span><span class="ident">F</span>: <span class="ident">Float</span><span class="op">&gt;</span> <span class="ident">SvmParams</span><span class="op">&lt;</span><span class="ident">F</span>, <span class="ident">F</span><span class="op">&gt;</span> {
    <span class="doccomment">/// Set the C value for regression</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">c_eps</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">c</span>: <span class="ident">F</span>, <span class="ident">eps</span>: <span class="ident">F</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">c</span> <span class="op">=</span> <span class="prelude-val">Some</span>((<span class="ident">c</span>, <span class="ident">eps</span>));
        <span class="self">self</span>.<span class="ident">nu</span> <span class="op">=</span> <span class="prelude-val">None</span>;

        <span class="self">self</span>
    }

    <span class="doccomment">/// Set the Nu-Eps value for regression</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">nu_eps</span>(<span class="kw-2">mut</span> <span class="self">self</span>, <span class="ident">nu</span>: <span class="ident">F</span>, <span class="ident">eps</span>: <span class="ident">F</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="self">Self</span> {
        <span class="self">self</span>.<span class="ident">nu</span> <span class="op">=</span> <span class="prelude-val">Some</span>((<span class="ident">nu</span>, <span class="ident">eps</span>));
        <span class="self">self</span>.<span class="ident">c</span> <span class="op">=</span> <span class="prelude-val">None</span>;

        <span class="self">self</span>
    }
}

<span class="doccomment">/// Reason for stopping</span>
<span class="doccomment">///</span>
<span class="doccomment">/// SMO can either exit because a threshold is reached or the iterations are maxed out. To</span>
<span class="doccomment">/// differentiate between both this flag is passed with the solution.</span>
<span class="attribute">#[<span class="ident">cfg_attr</span>(
    <span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;serde&quot;</span>,
    <span class="ident">derive</span>(<span class="ident">Serialize</span>, <span class="ident">Deserialize</span>),
    <span class="ident">serde</span>(<span class="kw">crate</span> <span class="op">=</span> <span class="string">&quot;serde_crate&quot;</span>)
)]</span>
<span class="attribute">#[<span class="ident">derive</span>(<span class="ident">Debug</span>)]</span>
<span class="kw">pub</span> <span class="kw">enum</span> <span class="ident">ExitReason</span> {
    <span class="ident">ReachedThreshold</span>,
    <span class="ident">ReachedIterations</span>,
}

<span class="doccomment">/// Fitted Support Vector Machines model</span>
<span class="doccomment">///</span>
<span class="doccomment">/// This is the result of the SMO optimizer and contains the support vectors, quality of solution</span>
<span class="doccomment">/// and optionally the linear hyperplane.</span>
<span class="attribute">#[<span class="ident">cfg_attr</span>(
    <span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;serde&quot;</span>,
    <span class="ident">derive</span>(<span class="ident">Serialize</span>, <span class="ident">Deserialize</span>),
    <span class="ident">serde</span>(<span class="kw">crate</span> <span class="op">=</span> <span class="string">&quot;serde_crate&quot;</span>)
)]</span>

<span class="kw">pub</span> <span class="kw">struct</span> <span class="ident">Svm</span><span class="op">&lt;</span><span class="ident">F</span>: <span class="ident">Float</span>, <span class="ident">T</span><span class="op">&gt;</span> {
    <span class="kw">pub</span> <span class="ident">alpha</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">F</span><span class="op">&gt;</span>,
    <span class="kw">pub</span> <span class="ident">rho</span>: <span class="ident">F</span>,
    <span class="ident">r</span>: <span class="prelude-ty">Option</span><span class="op">&lt;</span><span class="ident">F</span><span class="op">&gt;</span>,
    <span class="ident">exit_reason</span>: <span class="ident">ExitReason</span>,
    <span class="ident">iterations</span>: <span class="ident">usize</span>,
    <span class="ident">obj</span>: <span class="ident">F</span>,
    <span class="attribute">#[<span class="ident">cfg_attr</span>(
        <span class="ident">feature</span> <span class="op">=</span> <span class="string">&quot;serde&quot;</span>,
        <span class="ident">serde</span>(<span class="ident">bound</span>(
            <span class="ident">serialize</span> <span class="op">=</span> <span class="string">&quot;&amp;&#39;a Kernel&lt;&#39;a, F&gt;: Serialize&quot;</span>,
            <span class="ident">deserialize</span> <span class="op">=</span> <span class="string">&quot;&amp;&#39;a Kernel&lt;&#39;a, F&gt;: Deserialize&lt;&#39;de&gt;&quot;</span>
        ))
    )]</span>
    <span class="comment">// the only thing I need the kernel for after the training is to</span>
    <span class="comment">// compute the distances, but for that I only need the kernel method</span>
    <span class="comment">// and not the whole inner matrix</span>
    <span class="ident">kernel_method</span>: <span class="ident">KernelMethod</span><span class="op">&lt;</span><span class="ident">F</span><span class="op">&gt;</span>,
    <span class="ident">sep_hyperplane</span>: <span class="ident">SeparatingHyperplane</span><span class="op">&lt;</span><span class="ident">F</span><span class="op">&gt;</span>,
    <span class="ident">phantom</span>: <span class="ident">PhantomData</span><span class="op">&lt;</span><span class="ident">T</span><span class="op">&gt;</span>,
}

<span class="kw">impl</span><span class="op">&lt;</span><span class="ident">F</span>: <span class="ident">Float</span>, <span class="ident">T</span><span class="op">&gt;</span> <span class="ident">Svm</span><span class="op">&lt;</span><span class="ident">F</span>, <span class="ident">T</span><span class="op">&gt;</span> {
    <span class="doccomment">/// Create hyper parameter set</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// This creates a `SvmParams` and sets it to the default values:</span>
    <span class="doccomment">///  * C values of (1, 1)</span>
    <span class="doccomment">///  * Eps of 1e-7</span>
    <span class="doccomment">///  * No shrinking</span>
    <span class="doccomment">///  * Linear kernel</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">params</span>() <span class="op">-</span><span class="op">&gt;</span> <span class="ident">SvmParams</span><span class="op">&lt;</span><span class="ident">F</span>, <span class="ident">T</span><span class="op">&gt;</span> {
        <span class="ident">SvmParams</span> {
            <span class="ident">c</span>: <span class="prelude-val">Some</span>((<span class="ident">F</span>::<span class="ident">one</span>(), <span class="ident">F</span>::<span class="ident">one</span>())),
            <span class="ident">nu</span>: <span class="prelude-val">None</span>,
            <span class="ident">solver_params</span>: <span class="ident">SolverParams</span> {
                <span class="ident">eps</span>: <span class="ident">F</span>::<span class="ident">from</span>(<span class="number">1e-7</span>).<span class="ident">unwrap</span>(),
                <span class="ident">shrinking</span>: <span class="bool-val">false</span>,
            },
            <span class="ident">phantom</span>: <span class="ident">PhantomData</span>,
            <span class="ident">kernel</span>: <span class="ident">Kernel</span>::<span class="ident">params</span>().<span class="ident">method</span>(<span class="ident">KernelMethod</span>::<span class="ident">Linear</span>),
        }
    }

    <span class="doccomment">/// Returns the number of support vectors</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// This function returns the number of support vectors which have an influence on the decision</span>
    <span class="doccomment">/// outcome greater than zero.</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">nsupport</span>(<span class="kw-2">&amp;</span><span class="self">self</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="ident">usize</span> {
        <span class="self">self</span>.<span class="ident">alpha</span>
            .<span class="ident">iter</span>()
            <span class="comment">// around 1e-5 for f32 and 2e-14 for f64</span>
            .<span class="ident">filter</span>(<span class="op">|</span><span class="ident">x</span><span class="op">|</span> <span class="ident">x</span>.<span class="ident">abs</span>() <span class="op">&gt;</span> <span class="ident">F</span>::<span class="ident">from</span>(<span class="number">100.</span>).<span class="ident">unwrap</span>() <span class="op">*</span> <span class="ident">F</span>::<span class="ident">epsilon</span>())
            .<span class="ident">count</span>()
    }
    <span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">fn</span> <span class="ident">with_phantom</span><span class="op">&lt;</span><span class="ident">S</span><span class="op">&gt;</span>(<span class="self">self</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="ident">Svm</span><span class="op">&lt;</span><span class="ident">F</span>, <span class="ident">S</span><span class="op">&gt;</span> {
        <span class="ident">Svm</span> {
            <span class="ident">alpha</span>: <span class="self">self</span>.<span class="ident">alpha</span>,
            <span class="ident">rho</span>: <span class="self">self</span>.<span class="ident">rho</span>,
            <span class="ident">r</span>: <span class="self">self</span>.<span class="ident">r</span>,
            <span class="ident">exit_reason</span>: <span class="self">self</span>.<span class="ident">exit_reason</span>,
            <span class="ident">obj</span>: <span class="self">self</span>.<span class="ident">obj</span>,
            <span class="ident">iterations</span>: <span class="self">self</span>.<span class="ident">iterations</span>,
            <span class="ident">sep_hyperplane</span>: <span class="self">self</span>.<span class="ident">sep_hyperplane</span>,
            <span class="ident">kernel_method</span>: <span class="self">self</span>.<span class="ident">kernel_method</span>,
            <span class="ident">phantom</span>: <span class="ident">PhantomData</span>,
        }
    }

    <span class="doccomment">/// Sums the inner product of `sample` and every one of the support vectors.</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// ## Parameters</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// * `sample`: the input sample</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// ## Returns</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// The sum of all inner products of `sample` and every one of the support vectors, scaled by their weight.</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// ## Panics</span>
    <span class="doccomment">///</span>
    <span class="doccomment">/// If the shape of `sample` is not compatible with the</span>
    <span class="doccomment">/// shape of the support vectors</span>
    <span class="kw">pub</span> <span class="kw">fn</span> <span class="ident">weighted_sum</span><span class="op">&lt;</span><span class="ident">D</span>: <span class="ident">Data</span><span class="op">&lt;</span><span class="ident">Elem</span> <span class="op">=</span> <span class="ident">F</span><span class="op">&gt;</span><span class="op">&gt;</span>(<span class="kw-2">&amp;</span><span class="self">self</span>, <span class="ident">sample</span>: <span class="kw-2">&amp;</span><span class="ident">ArrayBase</span><span class="op">&lt;</span><span class="ident">D</span>, <span class="ident">Ix1</span><span class="op">&gt;</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="ident">F</span> {
        <span class="kw">match</span> <span class="self">self</span>.<span class="ident">sep_hyperplane</span> {
            <span class="ident">SeparatingHyperplane</span>::<span class="ident">Linear</span>(<span class="kw-2">ref</span> <span class="ident">x</span>) <span class="op">=</span><span class="op">&gt;</span> <span class="ident">x</span>.<span class="ident">mul</span>(<span class="ident">sample</span>).<span class="ident">sum</span>(),
            <span class="ident">SeparatingHyperplane</span>::<span class="ident">WeightedCombination</span>(<span class="kw-2">ref</span> <span class="ident">supp_vecs</span>) <span class="op">=</span><span class="op">&gt;</span> <span class="ident">supp_vecs</span>
                .<span class="ident">outer_iter</span>()
                .<span class="ident">zip</span>(
                    <span class="self">self</span>.<span class="ident">alpha</span>
                        .<span class="ident">iter</span>()
                        .<span class="ident">filter</span>(<span class="op">|</span><span class="ident">a</span><span class="op">|</span> <span class="ident">a</span>.<span class="ident">abs</span>() <span class="op">&gt;</span> <span class="ident">F</span>::<span class="ident">from</span>(<span class="number">100.</span>).<span class="ident">unwrap</span>() <span class="op">*</span> <span class="ident">F</span>::<span class="ident">epsilon</span>()),
                )
                .<span class="ident">map</span>(<span class="op">|</span>(<span class="ident">x</span>, <span class="ident">a</span>)<span class="op">|</span> <span class="self">self</span>.<span class="ident">kernel_method</span>.<span class="ident">distance</span>(<span class="ident">x</span>, <span class="ident">sample</span>.<span class="ident">view</span>()) <span class="op">*</span> <span class="kw-2">*</span><span class="ident">a</span>)
                .<span class="ident">sum</span>(),
        }
    }
}

<span class="doccomment">/// Display solution</span>
<span class="doccomment">///</span>
<span class="doccomment">/// In order to understand the solution of the SMO solver the objective, number of iterations and</span>
<span class="doccomment">/// required support vectors are printed here.</span>
<span class="kw">impl</span><span class="op">&lt;</span><span class="lifetime">&#39;a</span>, <span class="ident">F</span>: <span class="ident">Float</span>, <span class="ident">T</span><span class="op">&gt;</span> <span class="ident">fmt</span>::<span class="ident">Display</span> <span class="kw">for</span> <span class="ident">Svm</span><span class="op">&lt;</span><span class="ident">F</span>, <span class="ident">T</span><span class="op">&gt;</span> {
    <span class="kw">fn</span> <span class="ident">fmt</span>(<span class="kw-2">&amp;</span><span class="self">self</span>, <span class="ident">f</span>: <span class="kw-2">&amp;</span><span class="kw-2">mut</span> <span class="ident">fmt</span>::<span class="ident">Formatter</span><span class="op">&lt;</span><span class="lifetime">&#39;_</span><span class="op">&gt;</span>) <span class="op">-</span><span class="op">&gt;</span> <span class="ident">fmt</span>::<span class="prelude-ty">Result</span> {
        <span class="kw">match</span> <span class="self">self</span>.<span class="ident">exit_reason</span> {
            <span class="ident">ExitReason</span>::<span class="ident">ReachedThreshold</span> <span class="op">=</span><span class="op">&gt;</span> <span class="macro">write</span><span class="macro">!</span>(
                <span class="ident">f</span>,
                <span class="string">&quot;Exited after {} iterations with obj = {} and {} support vectors&quot;</span>,
                <span class="self">self</span>.<span class="ident">iterations</span>,
                <span class="self">self</span>.<span class="ident">obj</span>,
                <span class="self">self</span>.<span class="ident">nsupport</span>()
            ),
            <span class="ident">ExitReason</span>::<span class="ident">ReachedIterations</span> <span class="op">=</span><span class="op">&gt;</span> <span class="macro">write</span><span class="macro">!</span>(
                <span class="ident">f</span>,
                <span class="string">&quot;Reached maximal iterations {} with obj = {} and {} support vectors&quot;</span>,
                <span class="self">self</span>.<span class="ident">iterations</span>,
                <span class="self">self</span>.<span class="ident">obj</span>,
                <span class="self">self</span>.<span class="ident">nsupport</span>()
            ),
        }
    }
}

<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">test</span>)]</span>
<span class="kw">mod</span> <span class="ident">tests</span> {
    <span class="kw">use</span> <span class="kw">crate</span>::<span class="ident">Svm</span>;
    <span class="kw">use</span> <span class="ident">linfa</span>::<span class="ident">prelude</span>::<span class="kw-2">*</span>;

    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">test_iter_folding_for_classification</span>() {
        <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">dataset</span> <span class="op">=</span> <span class="ident">linfa_datasets</span>::<span class="ident">winequality</span>().<span class="ident">map_targets</span>(<span class="op">|</span><span class="ident">x</span><span class="op">|</span> <span class="kw-2">*</span><span class="ident">x</span> <span class="op">&gt;</span> <span class="number">6</span>);
        <span class="kw">let</span> <span class="ident">params</span> <span class="op">=</span> <span class="ident">Svm</span>::<span class="ident">params</span>().<span class="ident">pos_neg_weights</span>(<span class="number">7.</span>, <span class="number">0.6</span>).<span class="ident">gaussian_kernel</span>(<span class="number">80.0</span>);

        <span class="kw">let</span> <span class="ident">avg_acc</span> <span class="op">=</span> <span class="ident">dataset</span>
            .<span class="ident">iter_fold</span>(<span class="number">4</span>, <span class="op">|</span><span class="ident">training_set</span><span class="op">|</span> <span class="ident">params</span>.<span class="ident">fit</span>(<span class="kw-2">&amp;</span><span class="ident">training_set</span>).<span class="ident">unwrap</span>())
            .<span class="ident">map</span>(<span class="op">|</span>(<span class="ident">model</span>, <span class="ident">valid</span>)<span class="op">|</span> {
                <span class="ident">model</span>
                    .<span class="ident">predict</span>(<span class="ident">valid</span>.<span class="ident">view</span>())
                    .<span class="ident">map_targets</span>(<span class="op">|</span><span class="ident">x</span><span class="op">|</span> <span class="kw-2">*</span><span class="kw-2">*</span><span class="ident">x</span> <span class="op">&gt;</span> <span class="number">0.0</span>)
                    .<span class="ident">confusion_matrix</span>(<span class="kw-2">&amp;</span><span class="ident">valid</span>)
                    .<span class="ident">unwrap</span>()
                    .<span class="ident">accuracy</span>()
            })
            .<span class="ident">sum</span>::<span class="op">&lt;</span><span class="ident">f32</span><span class="op">&gt;</span>()
            <span class="op">/</span> <span class="number">4_f32</span>;
        <span class="macro">assert</span><span class="macro">!</span>(<span class="ident">avg_acc</span> <span class="op">&gt;</span><span class="op">=</span> <span class="number">0.5</span>)
    }

    <span class="comment">/*#[test]
    fn test_iter_folding_for_regression() {
        let mut dataset: Dataset&lt;f64, f64&gt; = linfa_datasets::diabetes();
        let params = Svm::params().linear_kernel().c_eps(100., 1.);

        let _avg_r2 = dataset
            .iter_fold(4, |training_set| params.fit(&amp;training_set).unwrap())
            .map(|(model, valid)| Array1::from(model.predict(valid.view())).r2(valid.targets()))
            .sum::&lt;f64&gt;()
            / 4_f64;
    }*/</span>
}
</pre></div>
</section><section id="search" class="content hidden"></section><section class="footer"></section><div id="rustdoc-vars" data-root-path="../../" data-current-crate="linfa_svm"></div>
    <script src="../../main.js"></script><script src="../../source-script.js"></script><script src="../../source-files.js"></script><script defer src="../../search-index.js"></script></body></html>